{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataChallenge.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamilaandimen/MLCoursera/blob/master/DataChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK2J7xzXXtzq",
        "colab_type": "text"
      },
      "source": [
        "# **Data Challenge - MDI 341**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVY0Q-hIqAB9",
        "colab_type": "text"
      },
      "source": [
        "### Description\n",
        "\n",
        "The goal of this challenge is to develop a binary classification system which tries to detect if an image contains some property not (you can try to discover what these \"properties\" are).\n",
        "\n",
        "As opposed to the previous challenge, we will follow a different procedure in this challenge. The challenge will have two phases. Please read the below information carefully.\n",
        "\n",
        "**In the first phase** of the challenge, you will be provided a training dataset which contains the raw images and their corresponding labels. We will also provide you a validation dataset, which only contains the raw images. The labes of the validation set will not be provided. In this phase, you will train your system based on this data and the ranking in the challenge webpage will be based on your score obtained on the validation data.\n",
        "\n",
        "\n",
        "**The second phase** of the challenge will start only a few hours (at most one day) before the deadline. Within this period, we will provide you the test set. You will need to run the algorithm that you developed on the first phase on this dataset and submit your predictions to the challenge webpage. Your final ranks will be determined on this dataset. Note that this phase will only last a few hours, which means that you will not be able to tune your algorithm on this dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls75rAYWqIXt",
        "colab_type": "text"
      },
      "source": [
        "### Properties of the data set\n",
        "\n",
        "- Training data:\n",
        "\n",
        "The training set contains raw images and their labels. There are 116157 images in this dataset. Each image is of size 56 x 56 x 3 (the last dimension encodes the color information: red-green-blue). For each image there is a label, either 0 or 1.\n",
        "\n",
        "- Validation data:\n",
        "\n",
        "The validation set only contains raw images. There are 27013 images in this dataset, where the image format is the same as before. The labels of this dataset will not be provided. Within the first phase, your ranks will be calculated based on this dataset.\n",
        "\n",
        "- Test data:\n",
        "\n",
        "The test set only contains raw images as well. There will be 59429 images in this dataset, where the image format is the same as before. The labels of this dataset will not be provided either. This dataset will be provided only in the second phase: only a couple of hours before the challenge deadline. Your final ranks will be calculated based on this dataset.\n",
        "\n",
        "Download link :\n",
        "- Train Images: https://www.dropbox.com/s/486li09u91zyjdm/db_train.raw\n",
        "\n",
        "- Labels: https://www.dropbox.com/s/d2hsorvtla3rtf9/label_2019_train.txt\n",
        "\n",
        "- Validation Images: https://www.dropbox.com/s/qonk627t2557utz/db_val.raw\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypT4zBTuqTa3",
        "colab_type": "text"
      },
      "source": [
        "### Performance Criteria\n",
        "\n",
        "As you will observe after examining the dataset, the data is highly unbalanced. Therefore, we choose a suitable criterion for evaluation: the performance criterion will be the average accuracy for each class.\n",
        "\n",
        "As an example, if all your predictions are 0, then your score will be 50%. The higher the score, the better the performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAfvvHoQlBTf",
        "colab_type": "text"
      },
      "source": [
        "# I. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QOHGjpbK8hO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d34f3d92-817f-4e5c-eef4-c3b0f8a156bc"
      },
      "source": [
        "!unzip \"BETvsYFT.zip\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  BETvsYFT.zip\n",
            "replace BETvsYFT/BET/1.PNG? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUUTPvPtXMVn",
        "colab_type": "text"
      },
      "source": [
        "## 1. Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gspbXs-1YJgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### General Imports ###\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "import math\n",
        "from time import time\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "!pip3 install --quiet ggplot\n",
        "\n",
        "#from ggplot import *\n",
        "\n",
        "### Visualization ###\n",
        "import time\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "### Deep Learning models ###\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model, model_from_json, Sequential\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, SeparableConv2D, ZeroPadding2D, UpSampling2D, BatchNormalization, Input, GlobalAveragePooling2D, AveragePooling2D\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Lambda\n",
        "\n",
        "from tensorflow.keras.applications import densenet\n",
        "\n",
        "### Large Scale Kernel ###\n",
        "from scipy.sparse.linalg import svds\n",
        "from scipy.linalg import svd\n",
        "from scipy.sparse import csc_matrix\n",
        "from numpy.linalg import multi_dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "### Classifiers ###\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### HOG features ###\n",
        "import scipy.misc\n",
        "import dlib\n",
        "import cv2\n",
        "from skimage.feature import hog\n",
        "\n",
        "### Image augmentation ###\n",
        "import random\n",
        "from scipy import ndarray\n",
        "import skimage as sk\n",
        "from skimage import transform\n",
        "from skimage import util\n",
        "import skimage.io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmW1Lwm2P4Mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rGqQvCDfIQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "from keras.layers import Flatten, Dense, Input, GlobalAveragePooling2D, \\\n",
        "    GlobalMaxPooling2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, \\\n",
        "    AveragePooling2D, Reshape, Permute, multiply\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "from keras.engine.topology import get_source_inputs\n",
        "import warnings\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "\n",
        "from functools import partial\n",
        "from keras.models import Model\n",
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Input\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import add"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U1IRUX7OrP8",
        "colab_type": "text"
      },
      "source": [
        "If we use the TPU (Autoencoder faces issues) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsAwbyUHZf7t",
        "colab_type": "code",
        "outputId": "c92b2b33-e185-46e2-9639-d1ddc157e4e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "try:\n",
        "    device_name = os.environ['COLAB_TPU_ADDR']\n",
        "    TPU_ADDRESS = 'grpc://' + device_name\n",
        "    print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "except KeyError:\n",
        "    print('TPU not found')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5agd-B8Zi5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_to_tpu(model):\n",
        "    return tf.contrib.tpu.keras_to_tpu_model( model, strategy=tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ6G5zvEXTp3",
        "colab_type": "text"
      },
      "source": [
        "## 2. Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbhhVIluUodv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxACsRPNY7Bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shape_x = 224\n",
        "shape_y = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDtzzvgjRwbg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "acf5840e-2e28-4693-b720-aab2f9027ec1"
      },
      "source": [
        "\"\"\"Split in 2 train and validation\"\"\"\n",
        "import os\n",
        "import random\n",
        "from shutil import copyfile, rmtree\n",
        "train_path =  '/content/BETvsYFT/'\n",
        "new_train_path = '/content/train/'\n",
        "new_val_path = '/content/validation/'\n",
        "new_test_path = '/content/test/'\n",
        "try:\n",
        "    \n",
        "    rmtree(new_train_path)\n",
        "    rmtree(new_val_path)\n",
        "    rmtree(new_test_path)\n",
        "    \n",
        "  \n",
        "except:\n",
        "    \n",
        "    pass\n",
        "try:\n",
        "  os.mkdir(new_train_path)\n",
        "  os.mkdir(new_test_path)\n",
        "  os.mkdir(new_val_path)\n",
        "except:\n",
        "\n",
        "       pass\n",
        "train_pct = 0.8\n",
        "val_pct = 0.1\n",
        "test_pct = 0.1\n",
        "for dir_ in os.listdir(train_path):\n",
        "    if os.path.isdir(train_path+dir_):\n",
        "        try:\n",
        "            os.mkdir(new_train_path+dir_)\n",
        "            os.mkdir(new_val_path+dir_)\n",
        "            os.mkdir(new_test_path+dir_)\n",
        "        except:\n",
        "\n",
        "            pass\n",
        "        pics = os.listdir(train_path+dir_)\n",
        "        random.shuffle(pics)\n",
        "        \n",
        "        train_stop_index = int(len(pics)*train_pct)\n",
        "        val_stop_index = int(len(pics)*(train_pct+val_pct))\n",
        "        train_pics = pics[:train_stop_index]\n",
        "        val_pics = pics[train_stop_index:val_stop_index] \n",
        "        test_pics = pics[val_stop_index:]\n",
        "\n",
        "        for pic in train_pics:\n",
        "            copyfile(train_path+dir_+\"/\"+pic,new_train_path+dir_+\"/\"+pic)\n",
        "        for pic in val_pics:\n",
        "            copyfile(train_path+dir_+\"/\"+pic,new_val_path+dir_+\"/\"+pic)            \n",
        "        for pic in test_pics:\n",
        "            copyfile(train_path+dir_+\"/\"+pic,new_test_path+dir_+\"/\"+pic)\n",
        "            \n",
        "def count_files(directory):\n",
        "    counter = 0\n",
        "    for dir_ in os.listdir(directory):\n",
        "        if os.path.isdir(directory+dir_):\n",
        "            temp = len(os.listdir(directory+dir_))\n",
        "            print(dir_, temp)\n",
        "            counter += temp\n",
        "    return counter\n",
        "  \n",
        "print(\"train\")\n",
        "train_count = count_files(new_train_path)\n",
        "print(\"val\")\n",
        "val_count = count_files(new_val_path)\n",
        "print(\"test\")\n",
        "test_count = count_files(new_test_path)\n",
        "\n",
        "print(train_count, val_count, test_count, sum((train_count, val_count, test_count)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "BET 32\n",
            "YFT 37\n",
            "val\n",
            "BET 4\n",
            "YFT 5\n",
            "test\n",
            "BET 4\n",
            "YFT 5\n",
            "69 9 9 87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xno56HyQKoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "47c68671-e8e7-4a25-d6b5-0b428ed14f0d"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/train',\n",
        "        target_size=(200, 200),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/validation',\n",
        "        target_size=(200, 200),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\"\"\"\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 69 images belonging to 2 classes.\n",
            "Found 9 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hka4SPUyV15x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "train_images_fname = 'drive/My Drive/db_train.raw'\n",
        "train_labels_fname = 'drive/My Drive/label_2019_train.txt'\n",
        "\n",
        "val_images_fname    = 'drive/My Drive/db_val.raw'\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# number of images\n",
        "num_train_images = 69\n",
        "num_valid_images = 9\n",
        "\n",
        "# size of the images 56*56 pixels in gray levels\n",
        "image_dim = shape_x * shape_y * 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HgcYXSCJL89",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "630e55bb-b96f-4f80-f02a-b2b12d34fcc5"
      },
      "source": [
        "\"\"\"y_train = np.loadtxt(train_labels_fname, dtype=np.float64)\n",
        "y_train_binary = tensorflow.keras.utils.to_categorical(y_train, 2)\n",
        "class_weight = {0 : sum(y_train)/len(y_train), 1 : (len(y_train)-sum(y_train))/len(y_train)}\n",
        "\"\"\""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'y_train = np.loadtxt(train_labels_fname, dtype=np.float64)\\ny_train_binary = tensorflow.keras.utils.to_categorical(y_train, 2)\\nclass_weight = {0 : sum(y_train)/len(y_train), 1 : (len(y_train)-sum(y_train))/len(y_train)}\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-GuQizpJKrC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2201eb5c-c80c-4f59-c5df-33a44c62851a"
      },
      "source": [
        "\"\"\"\n",
        "with open(train_images_fname, 'rb') as f:\n",
        "    X_train = np.fromfile(f, dtype=np.uint8, count=num_train_images * image_dim).astype(np.float32)/255\n",
        "    X_train = X_train.reshape(num_train_images, image_dim)\n",
        "\"\"\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nwith open(train_images_fname, 'rb') as f:\\n    X_train = np.fromfile(f, dtype=np.uint8, count=num_train_images * image_dim).astype(np.float32)/255\\n    X_train = X_train.reshape(num_train_images, image_dim)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw52EVJxP9WW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "256062e8-2b12-4d6b-c995-9640e23aeb14"
      },
      "source": [
        "\"\"\"\n",
        "with open(val_images_fname, 'rb') as f:\n",
        "    X_val = np.fromfile(f, dtype=np.uint8, count=num_valid_images * image_dim).astype(np.float32)\n",
        "    X_val = X_val.reshape(num_valid_images, image_dim)\n",
        "\"\"\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nwith open(val_images_fname, 'rb') as f:\\n    X_val = np.fromfile(f, dtype=np.uint8, count=num_valid_images * image_dim).astype(np.float32)\\n    X_val = X_val.reshape(num_valid_images, image_dim)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDHSi5FKXZjQ",
        "colab_type": "text"
      },
      "source": [
        "## 3. Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54zOTrtMWCWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f533db5e-bba8-4feb-dec3-66fee9f0b807"
      },
      "source": [
        "\"\"\"unique, counts = np.unique(y_train, return_counts=True)\"\"\""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'unique, counts = np.unique(y_train, return_counts=True)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTcQL7Nl261o",
        "colab_type": "code",
        "outputId": "f8ea2a1c-4673-41e5-f6d3-658033444d64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"unique, counts\"\"\""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'unique, counts'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3KLr6fLaxzf",
        "colab_type": "code",
        "outputId": "56a890ca-3f9a-4058-f978-4c0bba2f32c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"print(\"Number of observations belonging to class 0 : \" + str(counts[0] / (counts[0]+counts[1])))\"\"\""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"Number of observations belonging to class 0 : \" + str(counts[0] / (counts[0]+counts[1])))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGCwbe6zWXGP",
        "colab_type": "text"
      },
      "source": [
        "There is a slight class imbalance, but it shouldn't be a major issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvzLMYWQoonx",
        "colab_type": "text"
      },
      "source": [
        "### a. Visualize the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_I1MRSYWlSP",
        "colab_type": "code",
        "outputId": "d75e2f1a-32a2-4e75-e2d0-99ea406e4db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"# Investigation\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\"\"\""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Investigation\\nprint(X_train.shape)\\nprint(y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-IeesMfWv0x",
        "colab_type": "code",
        "outputId": "72c15fa1-f37b-4c70-c76b-a2978a5dc3ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"fig, axes = plt.subplots(nrows=1, ncols=8, figsize=(18, 4))\"\"\"\n",
        "\n",
        "\"\"\"for i, ax in enumerate(axes):\n",
        "    ax.imshow(X_train[i].reshape(shape_x, shape_y,3).astype(np.uint8))\n",
        "    ax.set_title(y_train[i])\n",
        "\"\"\""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for i, ax in enumerate(axes):\\n    ax.imshow(X_train[i].reshape(shape_x, shape_y,3).astype(np.uint8))\\n    ax.set_title(y_train[i])\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRBtCpiHogE_",
        "colab_type": "text"
      },
      "source": [
        "### b. Most important region"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNSMLVYhqmlT",
        "colab_type": "text"
      },
      "source": [
        "We don't know yet what the labels represent. For this reason, we'll try to identify the regions that are the most important by applying a feature importance over a XGBoost classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay0MQgguxuqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NQZdUFFxxAS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXRuenCFqmQZ",
        "colab_type": "code",
        "outputId": "18501a4e-7f14-4d8a-9615-abf4312cc15f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import optimizers\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.models import Model\n",
        "#Get back the convolutional part of a VGG network trained on ImageNet\n",
        "model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
        "model_vgg16_conv.summary()\n",
        "\n",
        "#Create your own input format (here 3x200x200)\n",
        "input = Input(shape=(200,200,3),name = 'image_input')\n",
        "\n",
        "#Use the generated model \n",
        "output_vgg16_conv = model_vgg16_conv(input)\n",
        "\n",
        "#Add the fully-connected layers \n",
        "x = Flatten(name='flatten')(output_vgg16_conv)\n",
        "x = Dense(4096, activation='relu', name='fc1')(x)\n",
        "x = Dense(4096, activation='relu', name='fc2')(x)\n",
        "x = Dense(2, activation='softmax', name='predictions')(x)\n",
        "\n",
        "#Create your own model \n",
        "model = Model(input=input, output=x)\n",
        "#model = VGG16()\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "#model.fit(X_train[:10000], y_train[:10000])\n",
        "\n",
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=2000,\n",
        "        epochs=50,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=800)\n",
        "# feature importance\n",
        "print(model.feature_importances_)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"im..., outputs=Tensor(\"pr...)`\n",
            "W0702 14:31:01.207460 139628377397120 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 609/2000 [========>.....................] - ETA: 40:22 - loss: 8.6039 - acc: 0.4654"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-090b69429093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         validation_steps=800)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;31m# feature importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11TxMrj5JRYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gray = cv2.cvtColor(model.feature_importances_.reshape(shape_x, shape_y,3), cv2.COLOR_BGR2GRAY)\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(gray)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBmT5gMZNMO1",
        "colab_type": "text"
      },
      "source": [
        "The eyes appear as the most important region we should focus on, and maybe the nose. To avoid adding noise to the image, we'll try to see if by setting an importance threshold, we are able to identify a specific region."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH4-SL1qy081",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
        "plt.axhline(y=0.003, color='r', linestyle='-')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTO7kFKfNgaf",
        "colab_type": "text"
      },
      "source": [
        "We'll choose 0.003 as a threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d-Nu-rZtwz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_importance = np.array(model.feature_importances_)>0.003\n",
        "new = feature_importance*np.array(model.feature_importances_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2IoOuU_sA-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gray = cv2.cvtColor(new.reshape(shape_x, shape_y, 3), cv2.COLOR_BGR2GRAY)\n",
        "plt.imshow(gray)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C-OQVqP1bQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_crop = X_train.reshape(-1,shape_x, shape_y, 3)[:,5:25,10:50,:]\n",
        "X_val_crop = X_val.reshape(-1,shape_x, shape_y, 3)[:,5:25,10:50,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqb7WXu41ime",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=8, figsize=(18, 4))\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.imshow(X_train_crop[i].astype(np.uint8))\n",
        "    ax.set_title(y_train[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5oQyRqLNk6y",
        "colab_type": "text"
      },
      "source": [
        "The eyes appear as the single most important region. However, since gradient boosting methods do not perform so well, there is a large risk to overfit if we focus on this region in particular. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvbK-KeGeJ01",
        "colab_type": "text"
      },
      "source": [
        "### c. Average picture "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngr3kMxneQdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Global average picture\n",
        "avg_pic = np.mean(X_train, axis=0).astype('int').reshape(shape_x, shape_y, 3)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.imshow(avg_pic)\n",
        "plt.title(\"Average Picture\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A92-c0q5e0is",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Average picture label 1\n",
        "avg_pic_1 = np.mean(X_train[np.where(y_train == 1)], axis=0).astype('int').reshape(shape_x, shape_y, 3)\n",
        "avg_pic_0 = np.mean(X_train[np.where(y_train == 0)], axis=0).astype('int').reshape(shape_x, shape_y, 3)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 10))\n",
        "\n",
        "axes[0].imshow(avg_pic_1)\n",
        "axes[0].set_title(\"Average Picture Label 1\")\n",
        "\n",
        "axes[1].imshow(avg_pic_0)\n",
        "axes[1].set_title(\"Average Picture Label 0\")\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96hfLYVogd1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Average substracted picture \n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.imshow(((avg_pic_1 - avg_pic_0)/np.max(avg_pic_1 - avg_pic_0)*255).astype('int'), 'gray')\n",
        "plt.title(\"Average difference Between Class 0 and 1\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUEL0yAejPUQ",
        "colab_type": "text"
      },
      "source": [
        "### d. Distribution of the colors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZWFNjUtl7ME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.distplot(avg_pic_1.flatten(), bins=80, kde=True, hist=True, label=\"Label 1\")\n",
        "sns.distplot(avg_pic_0.flatten(), bins=80, kde=True, hist=True, label=\"Label 0\")\n",
        "plt.title(\"Distribution of the color pixel values by label\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY0IqmHXwqsB",
        "colab_type": "text"
      },
      "source": [
        "### **e. Compare the train set and the validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKRwdepExYGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Total Elements in train : \" + str(len(X_train)))\n",
        "print(\"Unique Elements in train : \" + str(len(np.unique(X_train, axis=0))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxH1u0Mowy0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Total Elements in val : \" + str(len(X_val)))\n",
        "print(\"Unique Elements in val : \" + str(len(np.unique(X_val.reshape(-1,shape_x, shape_y,3), axis=0))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ts6YpJay4X8",
        "colab_type": "text"
      },
      "source": [
        "There's almost no duplicates among the train set and the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7dRugq3y931",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tot = np.concatenate((X_train, X_val), axis=0)\n",
        "print(\"Total Elements in Tot : \" + str(len(X_tot)))\n",
        "print(\"Unique Elements in Tot : \" + str(len(np.unique(X_tot.reshape(-1,800), axis=0))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TOVgYgy0Rvu",
        "colab_type": "text"
      },
      "source": [
        "We should be careful here. The images in the validation set are exactly the same than the ones in the training set. In order to prevent overfitting, we should :\n",
        "- always apply cross validation when choosing a technique\n",
        "- explore data augmentation techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P80gHz3wpXcy",
        "colab_type": "text"
      },
      "source": [
        "### **f. Cross validation functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysZffBlx8CfQ",
        "colab_type": "text"
      },
      "source": [
        "We need to define a custom cross validation function :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMaeuDQkQ8r3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Performance measure\n",
        "def compute_pred_score(estimator, X, y_true):\n",
        "  y_pred = estimator.predict(X)\n",
        "  if(y_true.shape[0] != y_pred.shape[0]):\n",
        "    raise Exception(\"y_pred and y_true must have the same size\")\n",
        "  tmp = np.unique(y_pred)\n",
        "  if(tmp.shape[0] > 2):\n",
        "    raise(\"y_pred should only contain 0 and 1\")\n",
        "        \n",
        "  if(tmp.shape[0] == 1):\n",
        "    if(tmp[0] != 0 and tmp[0] != 1):\n",
        "      raise Exception(\"y_pred should only contain 0 and 1\")\n",
        "  else:\n",
        "    if(tmp[0] != 0 and tmp[1] != 1):\n",
        "      raise Exception(\"y_pred should only contain 0 and 1\")\n",
        "    \n",
        "  y0 = (y_true == 0)\n",
        "  y1 = (y_true == 1)\n",
        "    \n",
        "  acc1 = np.mean(1-y_pred[y0])\n",
        "  acc2 = np.mean(y_pred[y1])\n",
        "    \n",
        "  return (acc1+acc2)/2\n",
        "\n",
        "def score(y_val, y_test) :\n",
        "  return K.mean(y_val*y_test + (1-y_val)*(1-y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0hy_x3I8cBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_val(estimator, X_train, y_train, cv) :\n",
        "  return cross_val_score(estimator, X_train, y_train, compute_pred_score, cv=cv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PveNMfgp2cGP",
        "colab_type": "text"
      },
      "source": [
        "**e. Data augmentation techniques**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyoTl17A2qpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_rotation(image_array: ndarray):\n",
        "    # pick a random degree of rotation between 25% on the left and 25% on the right\n",
        "    random_degree = random.uniform(-25, 25)\n",
        "    return sk.transform.rotate(image_array, random_degree)\n",
        "\n",
        "def random_noise(image_array: ndarray):\n",
        "    # add random noise to the image\n",
        "    return sk.util.random_noise(image_array)\n",
        "\n",
        "def horizontal_flip(image_array: ndarray):\n",
        "    # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n",
        "    return image_array[:, ::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mlDv7JKFbta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_files_desired = 25000\n",
        "\n",
        "# loop on all files of the folder and build a list of files paths\n",
        "\n",
        "num_generated_files = 0\n",
        "\n",
        "X_aug = X_train.copy()\n",
        "\n",
        "available_transformations = {\n",
        "    'rotate': random_rotation,\n",
        "    'noise': random_noise,\n",
        "    'horizontal_flip': horizontal_flip\n",
        "}\n",
        "\n",
        "while num_generated_files <= num_files_desired:\n",
        "\n",
        "    image_to_transform = random.choice(X_train.reshape(-1,20,40,1))\n",
        "    # random num of transformation to apply\n",
        "    num_transformations_to_apply = random.randint(1, len(available_transformations))\n",
        "\n",
        "    num_transformations = 0\n",
        "    \n",
        "    while num_transformations <= num_transformations_to_apply:\n",
        "        # random transformation to apply for a single image\n",
        "        key = random.choice(list(available_transformations))\n",
        "        modif_img = available_transformations[key](image_to_transform).reshape(1,20, 40, 1)\n",
        "\n",
        "        X_aug = np.concatenate((X_aug, modif_img), axis=0)\n",
        "        num_transformations += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnK-Mqtu175Y",
        "colab_type": "text"
      },
      "source": [
        "We'll explore several strategies :\n",
        "- apply a classifier on the flattened image\n",
        "- build an autoencoder to reduce the dimension of the data and apply a classifier on top\n",
        "- apply a convolutional neural network (CNN) on the input image\n",
        "- build more complex architectures using neural networks (Inception, XCeption...)\n",
        "- extract manually HOG and sliding HOG features and apply a SVM and a Random Kernel \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19bnVPiu1mtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In case this is needed later, transform the images to grayscale\n",
        "X_train = (0.21 * X_train[:,:,:,0] + 0.72 * X_train[:,:,:,1] + 0.07 * X_train[:,:,:,2]).astype('int').reshape(-1,20,40,1)\n",
        "X_val = (0.21 * X_val[:,:,:,0] + 0.72 * X_val[:,:,:,1] + 0.07 * X_val[:,:,:,2]).astype('int').reshape(-1,20,40,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBrLU1i4WOkQ",
        "colab_type": "text"
      },
      "source": [
        "# II. Predictive Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCDICv1_F9Ns",
        "colab_type": "text"
      },
      "source": [
        "## II.1 LGBM on flattened image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOZWTBMDQw0H",
        "colab_type": "text"
      },
      "source": [
        "### a. Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0vqyuWLQvKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = LGBMClassifier(learning_rate = 0.1, num_leaves = 30, n_estimators=1000, verbose=1)\n",
        "scores = cross_val_score(clf, X_train.reshape(-1,shape_x*shape_y*3), y_train, cv=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebvo5Acbwe_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean(scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU9pf6T-0yeQ",
        "colab_type": "text"
      },
      "source": [
        "The classifier in a flat image heads an accuracy of 74.578%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6H5OqLhSvbp",
        "colab_type": "text"
      },
      "source": [
        "### **b. Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7LhwdIGWMKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = LGBMClassifier(learning_rate = 0.1, num_leaves = 200, n_estimators=2000, verbose=1)\n",
        "clf.fit(x_train, label_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pg-OQaAWxH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'lgb.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oQbc5mrWerd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate the prediction\n",
        "val_pred = clf.predict(X_val)\n",
        "np.savetxt(\"val_pred_clf.txt\", val_pred, fmt=\"%d\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1ZwdLEZnIE-",
        "colab_type": "text"
      },
      "source": [
        "## II.2 Auto-Encoding for dimension reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAeLyMlKye5y",
        "colab_type": "text"
      },
      "source": [
        "### a. Define the autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz2HPtPs_ont",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input(shape=(shape_x, shape_y, 3))\n",
        "\n",
        "# Ecoding\n",
        "x = Conv2D(2, (3, 3), padding='same', activation='relu')(input_img)\n",
        "x = MaxPooling2D(pool_size=(2,2), padding='same')(x)\n",
        "encoded = Conv2D(1,(3, 3), padding='same', activation='relu')(x)\n",
        " \n",
        "# Decoding\n",
        "x = Conv2D(1,(3, 3), padding='same', activation='relu')(encoded)\n",
        "x = Conv2D(2,(3, 3), padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(3,(3, 3), padding='same', activation = 'linear')(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIzhO0hgAMlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6DWzMqadsif",
        "colab_type": "text"
      },
      "source": [
        "We'll fit our autoencoder an augmented data to avoid overfitting on the test part of the challenge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bow2G399eNd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 30\n",
        "batch_size = 16\n",
        "\n",
        "history = autoencoder.fit( (X_train).reshape(-1, shape_x, shape_y, 3), (X_train).reshape(-1, shape_x, shape_y, 3), batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qbk4Te-7GtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['loss'],'r',linewidth=2.0)\n",
        "plt.plot(history.history['val_loss'],'b',linewidth=2.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpjhEZpt7Iv0",
        "colab_type": "text"
      },
      "source": [
        "We can also implement an image data augmentation pipeline before fitting the encoder. There is however a potential issue with the data augmentation. Since the label is unknown, making data augmentation could mean that we loose some information (e.g if the label depends on the eye alignment...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJgTnSkvuSgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#autoencoder = model_to_tpu(autoencoder)\n",
        "datagen = ImageDataGenerator(\n",
        "        zoom_range=0.2,          # randomly zoom into images\n",
        "        rotation_range=10,       # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,   # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,    # randomly flip images\n",
        "        vertical_flip=False)     # randomly flip images\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 32\n",
        "\n",
        "autoencoder.fit_generator(\n",
        "    datagen.flow(X_train.reshape(-1, shape_x, shape_y, 3), X_train.reshape(-1, shape_x, shape_y, 3), batch_size=batch_size),\n",
        "    steps_per_epoch=int(np.ceil(X_train.shape[0] / float(batch_size))),\n",
        "    epochs = epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_hfD-GTCXEV",
        "colab_type": "text"
      },
      "source": [
        "We can save the trained encoder :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNAofKy7O9Lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save autoencoder weight\n",
        "json_string = autoencoder.to_json()\n",
        "autoencoder.save_weights('drive/My Drive/autoencoder_final.h5')\n",
        "open('drive/My Drive/autoencoder_final.h5', 'w').write(json_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm2qQu5YCr3-",
        "colab_type": "text"
      },
      "source": [
        "### b. Visualize the encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMTyq4a0bwv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Model(inputs = input_img, outputs = encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u899s2uz3Zyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_imgs = encoder.predict(X_train.reshape(-1,shape_x, shape_y, 3))\n",
        "decoded_imgs = autoencoder.predict(X_train.reshape(-1,shape_x, shape_y, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw9lk5OE_Oct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('drive/My Drive/X_train_enc_final.npy', encoded_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbiM_7_cTTE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 10  \n",
        "plt.figure(figsize=(20, 4))\n",
        "\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(X_train[i].astype('int').reshape(shape_x, shape_y, 3), cmap='gray')\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Encoded images\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(encoded_imgs[i].astype('int').reshape(28,28), cmap='gray')\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
        "    plt.imshow(decoded_imgs[i].astype('int').reshape(shape_x, shape_y, 3), cmap='gray')\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkiVPLOKHrmU",
        "colab_type": "text"
      },
      "source": [
        "Through auto-encoding, we partly loose the color information. This could imply some issues on the final model and potentially explain a poor performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loSjohsNfoVb",
        "colab_type": "text"
      },
      "source": [
        "### c. Visualize the encoded images using T-SNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucYx3AHVH83D",
        "colab_type": "text"
      },
      "source": [
        "T-SNE is often applied after a first large dimension reduction such as PCA. In this case, we apply T-SNE  after the auto-encoding to display our data in 2 dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RxFYgIgfn2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rndperm = np.random.permutation(np.reshape(encoded_imgs, (-1,28*28)).shape[0])\n",
        "\n",
        "n_sne = 7000\n",
        "\n",
        "time_start = time.time()\n",
        "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "tsne_results = tsne.fit_transform(np.reshape(encoded_imgs, (-1,28*28))[rndperm[:n_sne]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgav8m1Hjeej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tsne = pd.DataFrame(np.reshape(encoded_imgs, (-1,28*28))[rndperm[:n_sne],:])\n",
        "df_tsne['x-tsne'] = tsne_results[:,0]\n",
        "df_tsne['y-tsne'] = tsne_results[:,1]\n",
        "df_tsne['label'] = y_train.flatten()[rndperm[:n_sne]]\n",
        "\n",
        "chart = ggplot(df_tsne, aes(x='x-tsne', y='y-tsne', color='label') ) \\\n",
        "        + geom_point(size=70,alpha=0.1) \\\n",
        "        + ggtitle(\"tSNE dimensions colored by label\")\n",
        "chart"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAw3bvbtIVGO",
        "colab_type": "text"
      },
      "source": [
        "The representation does not bring clear representation of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha9redQRMwEV",
        "colab_type": "text"
      },
      "source": [
        "### d. Build a predictor on reduced data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2c3wOanT1_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_imgs = np.load('drive/My Drive/X_train_enc.npy')/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4_vy9Y1VFGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createModel():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(4, (3, 3), padding='same', input_shape=(28,28,1)))\n",
        "    model.add(Conv2D(8, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(16, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "    \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
        "    model.add(Dropout(0.20))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "    model.add(Dropout(0.20))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(512))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Dense(256))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(96))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Dense(2))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgRokOGkVPsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = createModel()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOW1b8x8VUER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 30\n",
        "\n",
        "history = model.fit(encoded_imgs.reshape(-1, 28, 28, 1), y_train_binary, batch_size=batch_size,validation_split=0.2,epochs = epochs, class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNpD9rnPWaYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['loss'],'r',linewidth=2.0)\n",
        "plt.plot(history.history['val_loss'],'b',linewidth=2.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=16)\n",
        " \n",
        "# Accuracy Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['acc'],'r',linewidth=2.0)\n",
        "plt.plot(history.history['val_acc'],'b',linewidth=2.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBvhBmUyVIxs",
        "colab_type": "text"
      },
      "source": [
        "The accuracy in validation has issues going beyond 81%. Let's now test it on augmented images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaLUj2S2rRNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        zoom_range=0.2,          # randomly zoom into images\n",
        "        rotation_range=10,       # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,   # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,    # randomly flip images\n",
        "        vertical_flip=False)     # randomly flip images\n",
        "\n",
        "model = createModel()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "batch_size =128\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit_generator(\n",
        "    datagen.flow(encoded_imgs.reshape(-1, 28, 28, 1), y_train_binary, batch_size=batch_size),\n",
        "    steps_per_epoch=int(np.ceil(X_train.shape[0] / float(batch_size))),\n",
        "    epochs = epochs,\n",
        "    class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTGWWUGwX5MJ",
        "colab_type": "text"
      },
      "source": [
        "## II.3 Large Scale Kernel Method SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euw1bZFIgrIy",
        "colab_type": "text"
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98vBoIDhlqM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_features(X_train, X_test, gamma, c, seed=42):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    n_samples, n_features = X_train.shape\n",
        "\n",
        "    W = np.random.normal(0, np.sqrt(2*gamma), (n_features, c))\n",
        "    b = np.random.uniform(0, 2*math.pi, (1,c))\n",
        "\n",
        "    X_new_train = np.sqrt(2/n_features) * np.cos(np.dot(X_train, W) + b)\n",
        "    X_new_test = np.sqrt(2/n_features) * np.cos(np.dot(X_test, W) + b)\n",
        "\n",
        "    return X_new_train, X_new_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWZdd1l4qdye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_samples, n_features = X_train.shape\n",
        "gamma = 1. / n_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJEeT5tFr3At",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z_train = random_features(X_train.reshape(-1,800), gamma, c=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKSAxIyUsCaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = LinearSVC(dual=False)\n",
        "scores = cross_val(clf, Z_train, y_train, cv=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbMvwWIfgvgE",
        "colab_type": "text"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZYTjd1MgyIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.fit(Z_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3s5LJEPb1b3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate the prediction\n",
        "val_pred = clf.predict(X_val)\n",
        "np.savetxt(\"drive/My Drive/val_pred_lsk.txt\", val_pred, fmt=\"%d\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfdJhn87ljxt",
        "colab_type": "text"
      },
      "source": [
        "## II.4 Convolutional Neural Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Uztee2uNl_O",
        "colab_type": "text"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CepU2CQaW89U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createModel():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(4, (3, 3), padding='same', input_shape=(shape_x,shape_y,3)))\n",
        "    model.add(Conv2D(8, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(16, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "    \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
        "    model.add(Dropout(0.20))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "    model.add(Dropout(0.20))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(512))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Dense(256))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(96))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Dense(2))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6FOkaBOZbX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = createModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfRdc1JTaHbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A-mHhkqLjiM",
        "colab_type": "text"
      },
      "source": [
        "### Fit with a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1bbYWOVaLHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 256\n",
        "epochs = 25\n",
        "\n",
        "history = model.fit(X_train.reshape(-1, 56, 56, 3), y_train_binary, batch_size=batch_size,validation_split=0.2,epochs = epochs, class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKAHrHAXtMqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['loss'],'r',linewidth=2.0)\n",
        "plt.plot(history.history['val_loss'],'b',linewidth=2.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=16)\n",
        " \n",
        "# Accuracy Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['acc'],'r',linewidth=2.0)\n",
        "plt.plot(history.history['val_acc'],'b',linewidth=2.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fwv3p0kL-Bm",
        "colab_type": "text"
      },
      "source": [
        "### Fit on the whole train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTiXrh0RMD3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(X_train.reshape(-1, 56, 56, 3), y_train_binary, batch_size=batch_size, epochs = epochs, class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3FtZgnEMI6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the weights\n",
        "model.save('drive/My Drive/cnn_final.h5')\n",
        "model.save_weights('drive/My Drive/cnn_final_weights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7PJqa9jMxGZ",
        "colab_type": "text"
      },
      "source": [
        "### Fit on Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LZQVIymM2xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        zoom_range=0.2,          # randomly zoom into images\n",
        "        rotation_range=10,       # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,   # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,    # randomly flip images\n",
        "        vertical_flip=False)     # randomly flip images\n",
        "\n",
        "model = createModel()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "batch_size =128\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit_generator(\n",
        "    datagen.flow(X_train.reshape(-1, shape_x, shape_y, 3), y_train_binary, batch_size=batch_size),\n",
        "    steps_per_epoch=int(np.ceil(X_train.shape[0] / float(batch_size))),\n",
        "    epochs = epochs,\n",
        "    class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHkLH8bSNS01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the weights\n",
        "model.save('drive/My Drive/cnn_aug_final.h5')\n",
        "model.save_weights('drive/My Drive/cnn_aug_final_weights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUSKUhjis4bs",
        "colab_type": "text"
      },
      "source": [
        "## II.5 DenseNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHK6fNXPuTDf",
        "colab_type": "text"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNQEnMOa8loL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_image = Input(shape=(shape_x, shape_y, 3))\n",
        "x = BatchNormalization()(input_image)\n",
        "\n",
        "base_model = densenet.DenseNet121(input_shape=(shape_x, shape_y, 3),\n",
        "                             classes = 2,\n",
        "                             weights=None,\n",
        "                             include_top=False,\n",
        "                             pooling='avg')\n",
        "\n",
        "\n",
        "x = base_model(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(2, activation='softmax', name='fc2')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tc51cZg9AVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(input_image, x)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daIxZpFjum8_",
        "colab_type": "text"
      },
      "source": [
        "### Fit with a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ1zcD3cuoCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        " \n",
        "batch_size = 256\n",
        "epochs = 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CWTy9DpusJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train.reshape(-1,shape_x,shape_y,3), y_train_binary, batch_size=batch_size, epochs = epochs,validation_split = 0.2, class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df_paQ9ACRQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['loss'],'r',linewidth=2.0)\n",
        "plt.plot(history.history['val_loss'],'b',linewidth=2.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=16)\n",
        " \n",
        "# Accuracy Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['acc'],'r',linewidth=2.0)\n",
        "plt.plot(history.history['val_acc'],'b',linewidth=2.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6bb7dtXuxyv",
        "colab_type": "text"
      },
      "source": [
        "### Fit on the whole train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRo-IbwcuxbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 50\n",
        "history = model.fit(X_train.reshape(-1,shape_x,shape_y,3), y_train_binary, batch_size=batch_size, epochs = epochs, class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz-BI9izvBGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the weights\n",
        "model.save('drive/My Drive/dense_final.h5')\n",
        "model.save_weights('drive/My Drive/dense_final_weights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WtU-BEsu0ks",
        "colab_type": "text"
      },
      "source": [
        "### Fit on Augmented Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhWNTZvBu1Gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        zoom_range=0.2,          # randomly zoom into images\n",
        "        rotation_range=10,       # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,   # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,    # randomly flip images\n",
        "        vertical_flip=False)     # randomly flip images\n",
        "\n",
        "model = createModel()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "batch_size =128\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit_generator(\n",
        "    datagen.flow(X_train.reshape(-1, shape_x, shape_y, 3), y_train_binary, batch_size=batch_size),\n",
        "    steps_per_epoch=int(np.ceil(X_train.shape[0] / float(batch_size))),\n",
        "    epochs = epochs,\n",
        "    class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju6bj7GLvG4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the weights\n",
        "model.save('drive/My Drive/dense_aug_final.h5')\n",
        "model.save_weights('drive/My Drive/dense_aug_final_weights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SDptG5f4hf4T"
      },
      "source": [
        "## II.6 ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pjBmGnYNo6K",
        "colab_type": "text"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQrvzPOqh6Gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.applications.resnet50\n",
        "\n",
        "input_image = Input(shape=(shape_x, shape_y, 3))\n",
        "x = BatchNormalization()(input_image)\n",
        "\n",
        "base_model = resnet50.ResNet50(weights= None, include_top=False, input_shape= (shape_x,shape_y,3))\n",
        "\n",
        "x = base_model(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(2, activation='softmax', name='fc2')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbozKGpJNr7J",
        "colab_type": "text"
      },
      "source": [
        "### Fit with a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8HbLU4aHHNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        " \n",
        "batch_size = 256\n",
        "epochs = 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Sy6rfXUHSI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train.reshape(-1,shape_x,shape_y,3), y_train_binary, batch_size=batch_size, epochs = epochs,validation_split = 0.2, class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVSDq64HuZwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['loss'],'r',linewidth=2.0)\n",
        "plt.plot(history.history['val_loss'],'b',linewidth=2.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=16)\n",
        " \n",
        "# Accuracy Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['acc'],'r',linewidth=2.0)\n",
        "plt.plot(history.history['val_acc'],'b',linewidth=2.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJCyTYjLNuUw",
        "colab_type": "text"
      },
      "source": [
        "### Fit on the whole train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8Ef-bMENxcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train.reshape(-1,shape_x,shape_y,3), y_train_binary, batch_size=batch_size, epochs = epochs, class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDQdACN7N992",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the weights\n",
        "model.save('drive/My Drive/inception_final.h5')\n",
        "model.save_weights('drive/My Drive/inception_final_weights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB2j8a7RNxy_",
        "colab_type": "text"
      },
      "source": [
        "### Fit on Augmented Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lykcpflON0zJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        zoom_range=0.2,          # randomly zoom into images\n",
        "        rotation_range=10,       # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,   # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,    # randomly flip images\n",
        "        vertical_flip=False)     # randomly flip images\n",
        "\n",
        "model = createModel()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit_generator(\n",
        "    datagen.flow(X_train.reshape(-1, shape_x, shape_y, 3), y_train_binary, batch_size=batch_size),\n",
        "    steps_per_epoch=int(np.ceil(X_train.shape[0] / float(batch_size))),\n",
        "    epochs = epochs,\n",
        "    class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3rnFpJOQObL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the weights\n",
        "model.save('drive/My Drive/inception_aug_final.h5')\n",
        "model.save_weights('drive/My Drive/inception_aug_final_weights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vNFO8wQ9-Te",
        "colab_type": "text"
      },
      "source": [
        "## II.6 XCeption Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFefeEn2iKsI",
        "colab_type": "text"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV-qUXX--C5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def entry_flow(inputs) :\n",
        "    \n",
        "    x = Conv2D(32, 3, strides = 2, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    x = Conv2D(64,3,padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    previous_block_activation = x\n",
        "    \n",
        "    for size in [64, 128, 256] :\n",
        "    \n",
        "        x = Activation('relu')(x)\n",
        "        x = SeparableConv2D(size, 3, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "    \n",
        "        x = Activation('relu')(x)\n",
        "        x = SeparableConv2D(size, 3, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        \n",
        "        x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "        \n",
        "        residual = Conv2D(size, 1, strides=2, padding='same')(previous_block_activation)\n",
        "        \n",
        "        x = tensorflow.keras.layers.Add()([x, residual])\n",
        "        previous_block_activation = x\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Z36D_w-FP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def middle_flow(x, num_blocks=8) :\n",
        "    \n",
        "    previous_block_activation = x\n",
        "    \n",
        "    for _ in range(num_blocks) :\n",
        "    \n",
        "        x = Activation('relu')(x)\n",
        "        x = SeparableConv2D(256, 3, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "    \n",
        "        x = Activation('relu')(x)\n",
        "        x = SeparableConv2D(256, 3, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        \n",
        "        x = Activation('relu')(x)\n",
        "        x = SeparableConv2D(256, 3, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        \n",
        "        x = tensorflow.keras.layers.Add()([x, previous_block_activation])\n",
        "        previous_block_activation = x\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPBC83Ml-H6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exit_flow(x) :\n",
        "    \n",
        "    previous_block_activation = x\n",
        "    \n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(256, 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(1024, 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "    \n",
        "    residual = Conv2D(1024, 1, strides=2, padding='same')(previous_block_activation)\n",
        "    x = tensorflow.keras.layers.Add()([x, residual])\n",
        "      \n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(1024, 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(2, activation='softmax')(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq-ZzC_LhS5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = Input(shape=(56, 56, 3))\n",
        "outputs = exit_flow(middle_flow(entry_flow(inputs)))\n",
        "xception = Model(inputs, outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DMFPOf9hTS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xception.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT29d1_oiQz4",
        "colab_type": "text"
      },
      "source": [
        "### Fit with a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnSJiNtPhrvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xception.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        " \n",
        "batch_size = 128\n",
        "epochs = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jKCK60khw2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = xception.fit(X_train.reshape(-1,56,56,3), y_train_binary, batch_size=batch_size, epochs = epochs, validation_split = 0.2 , class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCqL7ZBGiH8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['loss'],'r',linewidth=2.0)\n",
        "plt.plot(history.history['val_loss'],'b',linewidth=2.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=16)\n",
        " \n",
        "# Accuracy Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['acc'],'r',linewidth=2.0)\n",
        "plt.plot(history.history['val_acc'],'b',linewidth=2.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2x-GQuPQ_Dz",
        "colab_type": "text"
      },
      "source": [
        "### Fit on the whole train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONohyDSkQ91Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xception.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        " \n",
        "history = xception.fit(X_train.reshape(-1,56,56,3), y_train_binary, batch_size=batch_size, epochs = epochs, class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkIASPRCRF5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xception.save_weights('drive/My Drive/xception_final_weights')\n",
        "xception.save('drive/My Drive/xception_final.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ojv9Y0umRYII",
        "colab_type": "text"
      },
      "source": [
        "### Fit on Augmented Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZFINQBUxKMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        zoom_range=0.20,          # randomly zoom into images\n",
        "        rotation_range=10,       # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.10,   # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.10,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,    # randomly flip images\n",
        "        vertical_flip=False)     # randomly flip images\n",
        "\n",
        "epochs = 35\n",
        "batch_size = 128\n",
        "\n",
        "xception = Model(inputs, outputs)\n",
        "xception.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = xception.fit_generator(\n",
        "    datagen.flow(X_train.reshape(-1, shape_x, shape_y, 3), y_train_binary, batch_size=batch_size),\n",
        "    steps_per_epoch=int(np.ceil(X_train.shape[0] / float(batch_size))),\n",
        "    epochs = epochs,\n",
        "    class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tOj3RcozW0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xception.save_weights('drive/My Drive/xception_aug_3_final_weights')\n",
        "xception.save('drive/My Drive/xception_aug_3_final.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqeOFn9wyN3Q",
        "colab_type": "text"
      },
      "source": [
        "## II.8 VGG16 Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwS_DmDwSNOA",
        "colab_type": "text"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITacNQtqyNcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def VGG16(classes=2) :\n",
        "    input_shape = (shape_x,shape_y,3)\n",
        "\n",
        "    img_input = Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_1')(\n",
        "        img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_1')(\n",
        "        x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_2')(\n",
        "        x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_1')(\n",
        "        x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(\n",
        "        x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_3')(\n",
        "        x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_1')(\n",
        "        x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_2')(\n",
        "        x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_3')(\n",
        "        x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_1')(\n",
        "        x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_2')(\n",
        "        x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_3')(\n",
        "        x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool5')(x)\n",
        "\n",
        "    # Classification block\n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(4096, name='fc6')(x)\n",
        "    x = Activation('relu', name='fc6/relu')(x)\n",
        "    x = Dense(2048, name='fc7')(x)\n",
        "    x = Activation('relu', name='fc7/relu')(x)\n",
        "    x = Dense(1024, name='fc8')(x)\n",
        "    x = Activation('relu', name='fc8/relu')(x)\n",
        "    x = Dense(256, name='fc9')(x)\n",
        "    x = Activation('relu', name='fc9/relu')(x)\n",
        "    x = Dense(128, name='fc10')(x)\n",
        "    x = Activation('relu', name='fc10/relu')(x)\n",
        "    x = Dense(classes, name='fc11')(x)\n",
        "    x = Activation('softmax', name='fc11/softmax')(x)\n",
        "\n",
        "    model = Model(img_input, x, name='vggface_vgg16')  # load weights\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sntp3cZxBxS0",
        "colab_type": "text"
      },
      "source": [
        "### Fit with a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8HDB2Xhy9yK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "model = VGG16(classes=2)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train.reshape(-1,56,56,3), y_train_binary, batch_size=batch_size, epochs = epochs, validation_split=0.1, class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFVSceLWB_g-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['loss'],'r',linewidth=2.0)\n",
        "plt.plot(history.history['val_loss'],'b',linewidth=2.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=16)\n",
        " \n",
        "# Accuracy Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['acc'],'r',linewidth=2.0)\n",
        "plt.plot(history.history['val_acc'],'b',linewidth=2.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QwZwz01SUve",
        "colab_type": "text"
      },
      "source": [
        "### Fit on the whole train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmYp46nzSUbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train.reshape(-1,56,56,3), y_train_binary, batch_size=batch_size, epochs = epochs, class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdaCkNzjUmai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('drive/My Drive/vgg_final_weights')\n",
        "model.save('drive/My Drive/vgg_final.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3ug8jUvSXZ2",
        "colab_type": "text"
      },
      "source": [
        "### Fit on Augmented Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsSyHeXvArII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        zoom_range=0.2,          # randomly zoom into images\n",
        "        rotation_range=10,       # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,   # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,    # randomly flip images\n",
        "        vertical_flip=False)     # randomly flip images\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 256\n",
        "\n",
        "model = VGG16(classes=2)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "    datagen.flow(X_train.reshape(-1, shape_x, shape_y, 3), y_train_binary, batch_size=batch_size),\n",
        "    steps_per_epoch=int(np.ceil(X_train.shape[0] / float(batch_size))),\n",
        "    epochs = epochs,\n",
        "    class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6WYuQzaUvCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('drive/My Drive/vgg_aug_final_weights')\n",
        "model.save('drive/My Drive/vgg_aug_final.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH4PG2d8czla",
        "colab_type": "text"
      },
      "source": [
        "## II.9  HOG features and SVM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj3esgU9dF6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "window_size = 24\n",
        "window_step = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYko-wa3dmYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sliding_hog_windows(image):\n",
        "    hog_windows = []\n",
        "    for y in range(0, shape_x, window_step):\n",
        "        for x in range(0, shape_y, window_step):\n",
        "            window = image[y:y+window_size, x:x+window_size]\n",
        "            hog_windows.extend(hog(window, orientations=8, pixels_per_cell=(8, 8),\n",
        "                                            cells_per_block=(1, 1), visualise=False))\n",
        "    return hog_windows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q93luaoZdwNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hog_features = []\n",
        "hog_images = []\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    try:\n",
        "        # Build the image as an array\n",
        "        image = X_train[i].reshape((shape_x, shape_y, 3))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # HOG features\n",
        "        features, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualise=True)\n",
        "        hog_features.append(features)\n",
        "        hog_images.append(hog_image)\n",
        "\n",
        "    except Exception as e:\n",
        "        print( \"error in image: \" + str(i) + \" - \" + str(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJMb7TvfjCC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the HOG \n",
        "plt.imshow(images[0].reshape((shape_x, shape_y)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rinITgltg32l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SVC(random_state=42, max_iter=10000, kernel='rbf',gamma='auto')\n",
        "\n",
        "# Train\n",
        "model.fit(hog_features, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY0rkXiWh7m2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hog_features_test = []\n",
        "\n",
        "for i in range(len(X_val)):\n",
        "    try:\n",
        "        # Build the image as an array\n",
        "        image = X_train[i].reshape((shape_x, shape_y, 3))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # HOG features\n",
        "        features, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualise=True)\n",
        "        hog_features_test.append(features)\n",
        "\n",
        "    except Exception as e:\n",
        "        print( \"error in image: \" + str(i) + \" - \" + str(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRfowrMvhwBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate the prediction\n",
        "val_pred = model.predict(hog_features_test)\n",
        "np.savetxt(\"drive/My Drive/val_pred_hog.txt\", val_pred, fmt=\"%d\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c9K8Jkio0XM",
        "colab_type": "text"
      },
      "source": [
        "# III. Model soft probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdp61AjJozzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(X_train.reshape(-1, shape_x, shape_y, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf1_Gr5EpAdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.hist(pred, bins=500)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "216Dz4G1p--h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(pred))\n",
        "len(pred[pred > 0.2][pred[pred > 0.2]<0.8])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ql3ARNzSoj3",
        "colab_type": "text"
      },
      "source": [
        "# IV. Make predictions on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfnvXXdyWECW",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nbnsEYmWXdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images_fname = 'drive/My Drive/db_test.raw'\n",
        "num_test_images = 59429"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OnPzcARWK_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(test_images_fname, 'rb') as f:\n",
        "    X_test = np.fromfile(f, dtype=np.uint8, count=num_train_images * image_dim).astype(np.float32)\n",
        "    X_test = X_test.reshape(num_test_images, image_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTrck_DPxoVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=8, figsize=(18, 4))\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.imshow(X_test[i].reshape(shape_x, shape_y,3).astype(np.uint8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5uCgBgxWHA7",
        "colab_type": "text"
      },
      "source": [
        "## 2. Load the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W5v4q5CU7Bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_path_h5 = ['drive/My Drive/cnn_final.h5', \n",
        "                'drive/My Drive/inception_final.h5', \n",
        "                'drive/My Drive/xception_final.h5', \n",
        "                'drive/My Drive/facenet_final.h5',\n",
        "                'drive/My Drive/vgg_final.h5',\n",
        "                'drive/My Drive/dense_final.h5',\n",
        "                \n",
        "                \n",
        "                'drive/My Drive/cnn_aug_final.h5', \n",
        "                'drive/My Drive/inception_aug_final.h5', \n",
        "                'drive/My Drive/xception_aug_final.h5', \n",
        "                'drive/My Drive/xception_aug_3_final.h5', \n",
        "                'drive/My Drive/facenet_aug_final.h5',\n",
        "                'drive/My Drive/vgg_aug_final.h5',\n",
        "               ]\n",
        "\n",
        "model_chosen = list_path_h5[8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCmLGGMURMOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tensorflow.keras.models.load_model(model_chosen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K_3_wYdWyT5",
        "colab_type": "text"
      },
      "source": [
        "## 3. Make prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JabERg3vWxOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(X_test.reshape(-1, shape_x, shape_y, 3)).argmax(axis=-1)\n",
        "#pred = model.predict(X_val.reshape(-1, shape_x, shape_y, 3)).argmax(axis=-1)\n",
        "\n",
        "np.savetxt(\"drive/My Drive/prediction_dense_1.txt\", pred, fmt=\"%d\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m8MS7VXYMqp",
        "colab_type": "text"
      },
      "source": [
        "## 4. All predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j06UT1sYPC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in list_path_h5 :\n",
        "  model = tensorflow.keras.models.load_model(i)\n",
        "  pred = model.predict(X_test.reshape(-1, shape_x, shape_y, 3)).argmax(axis=-1)\n",
        "  np.savetxt(\"drive/My Drive/prediction_%d.txt\" %(i), val_pred, fmt=\"%d\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mm8t1mjRLl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Restore the weights\n",
        "#model = Model(inputs, outputs)\n",
        "#model.load_weights('drive/My Drive/xception_final_weights')\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfqAErdpkEbx",
        "colab_type": "text"
      },
      "source": [
        "# V. Ensemble model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSkjCw1CkD_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_path_h5 = ['drive/My Drive/cnn_final.h5', \n",
        "                'drive/My Drive/xception_final.h5', \n",
        "                'drive/My Drive/xception_aug_final.h5', \n",
        "                'drive/My Drive/xception_aug_3_final.h5', \n",
        "               ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CspybkI1kMSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pred = pd.DataFrame()\n",
        "\n",
        "for i in list_path_h5 :\n",
        "  model = tensorflow.keras.models.load_model(i)\n",
        "  pred = model.predict(X_train.reshape(-1, shape_x, shape_y, 3))\n",
        "  train_pred = pd.concat([train_pred, pd.DataFrame(pred)], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEtZ0KAOnziI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pred = pd.concat( [ \n",
        "    pd.DataFrame( np.array( (train_pred.iloc[:,0], train_pred.iloc[:,2], train_pred.iloc[:,4], train_pred.iloc[:,6]) )), \n",
        "    pd.DataFrame( np.array((train_pred.iloc[:,1], train_pred.iloc[:,3], train_pred.iloc[:,5], train_pred.iloc[:,7]) ))\n",
        "    ]).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmq_5b4_lizg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
        "clf.fit(train_pred, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlyaLBBBnI1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = pd.DataFrame()\n",
        "\n",
        "for i in list_path_h5 :\n",
        "  model = tensorflow.keras.models.load_model(i)\n",
        "  pred = model.predict(X_test.reshape(-1, shape_x, shape_y, 3))\n",
        "  test_pred = pd.concat([test_pred, pd.DataFrame(pred)], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpZvJ8DMqXaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = pd.concat( [ \n",
        "    pd.DataFrame( np.array( (test_pred.iloc[:,0], test_pred.iloc[:,2], test_pred.iloc[:,4], test_pred.iloc[:,6]) )), \n",
        "    pd.DataFrame( np.array((test_pred.iloc[:,1], test_pred.iloc[:,3], test_pred.iloc[:,5], test_pred.iloc[:,7]) ))\n",
        "    ]).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk2eoEIgnXen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = clf.predict(test_pred)\n",
        "np.savetxt(\"drive/My Drive/prediction_ensemble.txt\", pred, fmt=\"%d\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcaV6qVWs1xn",
        "colab_type": "text"
      },
      "source": [
        "# Optimize the train set (Not used)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPW6VFAaw28s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SikGn-3Fs6Dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwqoYqwqs84s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neighbors_idx_list = np.unique(np.ravel(knn.kneighbors(X_test)[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpWZaFUbtG7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_new = X_train.iloc[neighbors_idx_list, :]\n",
        "y_train_new = y_train.iloc[neighbors_idx_list]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}